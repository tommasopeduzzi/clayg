{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a81c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import os        \n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "from scipy.spatial import ConvexHull\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae22fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for plotting\n",
    "\n",
    "decoder_colors = {\n",
    "    'uf': [\n",
    "        \"#6baed6\", \"#4292c6\",\"#3182bd\", \"#1f77b4\", \"#2171b5\", \n",
    "        \"#08519c\", \"#08306b\", \"#08519c\", \"#08306b\", \"#08306b\",\n",
    "    ],\n",
    "    'clayg': [\n",
    "        \"#fdae6b\", \"#ffbb78\", \"#ff8c00\", \"#fd8d3c\", \"#ffa726\",\n",
    "        \"#f16913\", \"#ff7f0e\", \"#d95f02\", \"#d94801\", \"#a63603\",    \n",
    "    ],\n",
    "    'sl_clayg': [\n",
    "        \"#31a354\", \"#74c476\", \"#238b45\", \"#31a354\", \"#74c476\",\n",
    "        \"#006d2c\", \"#00441b\", \"#006d2c\", \"#00441b\", \"#006d2c\",\n",
    "    ],\n",
    "    'clayg_stop_early' : [\n",
    "        \"#525252\", \"#252525\", \"#737373\", \"#525252\", \"#252525\",\n",
    "        \"#000000\",\n",
    "    ],\n",
    "    'other': [\n",
    "        \"#e377c2\", \"#d62728\", \"#ff9896\", \"#c51b7d\", \"#8c564b\",\n",
    "        \"#e377c2\", \"#d62728\", \"#ff9896\", \"#c51b7d\", \"#8c564b\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "decoder_names = {\n",
    "    'uf': 'UF',\n",
    "    'clayg': 'ClAYG',\n",
    "    'sl_clayg': 'Single Layer ClAYG',\n",
    "    'clayg_third_growth': 'ClAYG ⅓ Growth',\n",
    "    'clayg_faster_backwards_growth': 'ClAYG w/ Faster Backwards Growth',\n",
    "    'sl_clayg_third_growth': 'Single Layer ClAYG ⅓ Growth',\n",
    "    'clayg_stop_early': 'ClAYG Stop Early',\n",
    "    'sl_clayg_stop_early': 'Single Layer ClAYG Stop Early',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c3da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot:\n",
    "    fig : go.Figure\n",
    "    title : str\n",
    "    def __init__(self, fig, title):\n",
    "        self.fig = fig\n",
    "        self.title = title\n",
    "        self.fig.update_layout(\n",
    "            title=self.title,\n",
    "        )\n",
    "    \n",
    "    def show(self):\n",
    "        # render into html\n",
    "        html = self.fig.to_html(full_html=True, include_plotlyjs='cdn')\n",
    "        html = html.replace('<head>', f'<head><title>{self.title}</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">')\n",
    "        # open in browser\n",
    "        file_name = self.title.replace(',', '').replace(' ', '_').lower()\n",
    "        file_name = f'plots/{file_name}.html'\n",
    "        with open(file_name, 'w') as f:\n",
    "            f.write(html)\n",
    "        os.system(f'xdg-open \"{file_name}\"')\n",
    "    \n",
    "    def set_title(self, title):\n",
    "        self.title = title\n",
    "        self.fig.update_layout(title=self.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f4ff851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_old(base_dir, plot_ids) -> pd.DataFrame:\n",
    "    data = pd.DataFrame(columns=[\"metric\", \"decoder\", \"distance\", \"p\", \"value\"])\n",
    "\n",
    "    for plot_id in plot_ids:\n",
    "        plot_folders = [f for f in glob.glob(os.path.join(base_dir, f\"{plot_id}-*\")) if os.path.isdir(f)]\n",
    "\n",
    "        if not plot_folders:\n",
    "            print(f\"No folders found for plot_id {plot_id}\")\n",
    "            continue\n",
    "        \n",
    "        folder = plot_folders[0]\n",
    "        files = glob.glob(os.path.join(folder, \"*.txt\"))\n",
    "\n",
    "        pattern = re.compile(r\"(average_operations|results)_(\\w+)_d=(\\d+)\\.txt\")\n",
    "        for file in files:\n",
    "            match = pattern.match(os.path.basename(file))\n",
    "            if not match:\n",
    "                continue\n",
    "            metric, decoder, distance = match.groups()\n",
    "            distance = int(distance)\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 2:\n",
    "                            key, value = parts\n",
    "                            # check if line is header or not\n",
    "                            if key == \"p\":\n",
    "                                continue\n",
    "                            try:\n",
    "                                p = float(key)\n",
    "                                value = float(value)\n",
    "                            except ValueError:\n",
    "                                print(f\"Skipping line with non-numeric key or value: {line.strip()}\")\n",
    "                                continue\n",
    "                            # add data to dataframe\n",
    "                            data.loc[len(data)] = {\n",
    "                                \"metric\": metric,\n",
    "                                \"decoder\": decoder,\n",
    "                                \"distance\": distance,\n",
    "                                \"p\": p,\n",
    "                                \"value\": value\n",
    "                            }\n",
    "    return data\n",
    "\n",
    "class Data:\n",
    "    results : pd.DataFrame\n",
    "    steps : pd.DataFrame\n",
    "\n",
    "def collect_data(base_dirs, plot_ids) -> Data:\n",
    "    data = Data()\n",
    "    data.results = pd.DataFrame(columns=[\"decoder\", \"distance\", \"p\", \"l\", \"n\", \"N\"])\n",
    "    data.steps = pd.DataFrame(columns=[\"decoder\", \"distance\", \"p\", \"value\", \"occurences\"])\n",
    "\n",
    "    plot_folders = []\n",
    "    for base_dir in base_dirs:\n",
    "        if not plot_ids:\n",
    "            plot_folders.extend([f for f in glob.glob(os.path.join(base_dir, \"*\")) if os.path.isdir(f)])\n",
    "        else:\n",
    "            for plot_id in plot_ids:\n",
    "                plot_folders.extend([f for f in glob.glob(os.path.join(base_dir, f\"{plot_id}*\")) if os.path.isdir(f)])\n",
    "    \n",
    "    for folder in plot_folders:\n",
    "        results_files = glob.glob(os.path.join(folder, \"results\", \"*.txt\"))\n",
    "        steps_files = glob.glob(os.path.join(folder, \"steps\", \"*.txt\"))\n",
    "        \n",
    "        results_file_pattern = re.compile(\n",
    "            r\"^(?P<decoder>(\\w+(?:_\\w+)*(?:_\\d+(?:\\.\\d+)*)?))_d=(?P<distance>\\d+)(?:_(?:idlingtimeconstant|N)=(?P<N>\\d+(?:\\.\\d+)?))?\\.txt$\"\n",
    "        )\n",
    "\n",
    "        for file in results_files:\n",
    "            match = results_file_pattern.match(os.path.basename(file))\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            decoder = match[\"decoder\"]\n",
    "            distance = int(match[\"distance\"])\n",
    "            N = float(match[\"N\"]) if match[\"N\"] else np.nan\n",
    "            \n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        try:\n",
    "                            if len(parts) == 2:\n",
    "                                key, value = parts\n",
    "                                n = None\n",
    "                            elif len(parts) == 3:\n",
    "                                key, value, n = parts\n",
    "                            else:\n",
    "                                raise ValueError(\"Unexpected number of parts in line\")\n",
    "                            p = float(key)\n",
    "                            l = float(value)\n",
    "                            n = float(n) if not n == None else None\n",
    "                        except ValueError:\n",
    "                            print(f\"Skipping line with NaN: {line.strip()}\")\n",
    "                            continue\n",
    "                        # add data to dataframe\n",
    "                        data.results.loc[len(data.results)] = {\n",
    "                            \"decoder\": decoder,\n",
    "                            \"distance\": distance,\n",
    "                            \"p\": p,\n",
    "                            \"l\": l,\n",
    "                            \"n\": n,\n",
    "                            \"N\": N,  \n",
    "                        }\n",
    "                                \n",
    "        steps_file_pattern = re.compile(r\"([\\w\\._]+)_d=(\\d+)_p=([\\d\\.]+)\\.txt\")\n",
    "        for file in steps_files: \n",
    "            steps_match = steps_file_pattern.match(os.path.basename(file))\n",
    "            if not steps_match:\n",
    "                continue\n",
    "            decoder, distance, p = steps_match.groups()\n",
    "            distance = int(distance)\n",
    "            p = float(p)\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 2:\n",
    "                            key, value = parts\n",
    "                            try:\n",
    "                                steps = float(key)\n",
    "                                occurences = int(value)\n",
    "                            except ValueError:\n",
    "                                print(f\"Skipping line with NaN: {line.strip()}\")\n",
    "                                continue\n",
    "                            # add data to dataframe\n",
    "                            data.steps.loc[len(data.steps)] = {\n",
    "                                \"decoder\": decoder,\n",
    "                                \"distance\": distance,\n",
    "                                \"p\": p,\n",
    "                                \"value\": steps,\n",
    "                                \"occurences\": occurences\n",
    "                            }\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b67db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1161008530.py, line 210)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 210\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mname=f'd={d} ɛ={eps}'\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def logical_vs_p_and_idlingtimconstant_plot(data: pd.DataFrame) -> Plot:\n",
    "    # 3d plot: l on z axis, p on y axis, 1/N on x axis, different plots for different distances\n",
    "    distances = sorted(data['distance'].unique())\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(len(distances) / cols))\n",
    "\n",
    "    # create 3D subplot grid (one scene per distance)\n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        specs=[[{'type': 'scene'} for _ in range(cols)] for _ in range(rows)],\n",
    "        subplot_titles=[f\"d={d}\" for d in distances]\n",
    "    )\n",
    "\n",
    "    seen_decoders = set()\n",
    "    for idx, distance in enumerate(distances):\n",
    "        row = idx // cols + 1\n",
    "        col = idx % cols + 1\n",
    "        df_d = data[data['distance'] == distance]\n",
    "        for decoder in df_d['decoder'].unique():\n",
    "            df_dec = df_d[df_d['decoder'] == decoder]\n",
    "            x = [1.0/val  if not np.isnan(val) else 0 for val in df_dec['N'].values]\n",
    "            y = df_dec['p'].values\n",
    "            z = df_dec['l'].values\n",
    "            colors = decoder_colors.get(decoder, ['#000000'])\n",
    "            color = colors[distance % len(colors)]\n",
    "            showlegend = decoder not in seen_decoders\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=x, y=y, z=z,\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=5, color=color),\n",
    "                    name=decoder_names.get(decoder, decoder),\n",
    "                    showlegend=showlegend\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            seen_decoders.add(decoder)\n",
    "\n",
    "    # set axis titles for every scene\n",
    "    for i in range(1, len(distances) + 1):\n",
    "        scene_key = 'scene' if i == 1 else f'scene{i}'\n",
    "        fig.update_layout(**{\n",
    "            scene_key: dict(\n",
    "                xaxis=dict(title='1/N'),\n",
    "                yaxis=dict(title='p'),\n",
    "                zaxis=dict(title='l')\n",
    "            )\n",
    "        })\n",
    "\n",
    "    fig.update_layout(title='Logical error rate vs p and 1/N (by distance)', showlegend=True)\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis_title='1/N',\n",
    "        yaxis_title='p',\n",
    "        zaxis_title='l',\n",
    "    ))\n",
    "    \n",
    "    return Plot(fig, \"Logical error rate vs p and idling time constant N⁻¹ (by distance)\")\n",
    "\n",
    "def idling_threshold_plots(data: pd.DataFrame, decoder_a: str, decoder_b: str, display_thresholds: bool = False) -> Plot:\n",
    "    # Expect columns: distance, decoder, N, p, l\n",
    "    distances = sorted(data['distance'].unique())\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(len(distances) / cols))\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        specs=[[{'type': 'heatmap'} for _ in range(cols)] for _ in range(rows)],\n",
    "        subplot_titles=[f\"d={d}\" for d in distances]\n",
    "    )\n",
    "\n",
    "    for idx, distance in enumerate(distances):\n",
    "        row, col = divmod(idx, cols)\n",
    "        row += 1\n",
    "        col += 1\n",
    "        df_d = data[data['distance'] == distance]\n",
    "\n",
    "        # Filter for just the two decoders\n",
    "        df_a = df_d[df_d['decoder'] == decoder_a].copy()\n",
    "        df_b = df_d[df_d['decoder'] == decoder_b].copy()\n",
    "        if df_a.empty or df_b.empty:\n",
    "            continue  # skip if one of them missing\n",
    "\n",
    "        # Merge on p and N to align values\n",
    "        merged = pd.merge(df_a, df_b, on=['p', 'N'], suffixes=('_a', '_b'))\n",
    "\n",
    "        # Compute relative difference (A vs B)\n",
    "        merged['inv_N'] = 1 / merged['N']\n",
    "        merged['rel_diff'] = (merged['l_a'] - merged['l_b']) / (0.5*(merged['l_a'] + merged['l_b']))\n",
    "\n",
    "        # Pivot for heatmap\n",
    "        pivot = merged.pivot_table(index='p', columns='inv_N', values='rel_diff')\n",
    "\n",
    "        # Add the heatmap\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=pivot.values,\n",
    "                x=pivot.columns,\n",
    "                y=pivot.index,\n",
    "                coloraxis = \"coloraxis\",\n",
    "                zmid=0,\n",
    "                name=f\"{decoder_a} vs {decoder_b}\",\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "        # --- Compute threshold (zero-crossing line) ---\n",
    "        thresholds = []\n",
    "        for invN, group in merged.groupby('inv_N'):\n",
    "            group = group.sort_values('p')\n",
    "            sign = np.sign(group['rel_diff'].values)\n",
    "            change_indices = np.where(np.diff(sign))[0]\n",
    "            if len(change_indices) > 0:\n",
    "                i0 = change_indices[0]\n",
    "                p1, p2 = group['p'].iloc[i0], group['p'].iloc[i0 + 1]\n",
    "                y1, y2 = group['rel_diff'].iloc[i0], group['rel_diff'].iloc[i0 + 1]\n",
    "                # Linear interpolation to find p where rel_diff = 0\n",
    "                p_thresh = p1 - y1 * (p2 - p1) / (y2 - y1)\n",
    "                thresholds.append((invN, p_thresh))\n",
    "\n",
    "        if thresholds and display_thresholds:\n",
    "            thresholds = np.array(sorted(thresholds, key=lambda t: t[0]))\n",
    "            thresholds = np.array(sorted(thresholds, key=lambda t: t[0]))\n",
    "            # rolling average (smooth p thresholds vs 1/N)\n",
    "            x = thresholds[:, 0].astype(float)\n",
    "            y = thresholds[:, 1].astype(float)\n",
    "            y_smooth = pd.Series(y).rolling(window=20, center=True, min_periods=1).mean().values\n",
    "\n",
    "            # plot raw (faint dashed) and smoothed (solid) threshold lines\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    mode='lines',\n",
    "                    line=dict(color='grey', width=1, dash='dash'),\n",
    "                    name=f\"threshold (raw) d={distance}\"\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x,\n",
    "                    y=y_smooth,\n",
    "                    mode='lines',\n",
    "                    line=dict(color='grey', width=2, shape='spline'),\n",
    "                    name=f\"threshold (rolling avg.) d={distance}\"\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Relative logical error rate and thresholds: {decoder_a} vs {decoder_b}\",\n",
    "        height=400 * rows,\n",
    "        showlegend=False,\n",
    "        coloraxis=dict(colorscale='RdBu', cmin=-1, cmax=1, colorbar=dict(title=f\"({decoder_a} - {decoder_b}) / ⟨{decoder_a}, {decoder_b}⟩\")),\n",
    "    )\n",
    "    fig.update_layout()\n",
    "\n",
    "    # Common axis labels\n",
    "    for i in range(1, len(distances) + 1):\n",
    "        fig.update_xaxes(title_text='1/N', row=(i - 1)//cols + 1, col=(i - 1)%cols + 1)\n",
    "        fig.update_yaxes(title_text='p', row=(i - 1)//cols + 1, col=(i - 1)%cols + 1)\n",
    "\n",
    "    return Plot(fig, f\"Relative logical error rate: {decoder_a} vs {decoder_b}\")\n",
    "\n",
    "def idling_threshold_comparison_plot(data: pd.DataFrame, decoder_a: str, decoder_b: str, eps: float = 0.1) -> Plot:\n",
    "    # Expect columns: distance, decoder, N, p, l\n",
    "    df_a = data[data['decoder'] == decoder_a].copy()\n",
    "    df_b = data[data['decoder'] == decoder_b].copy()\n",
    "\n",
    "    merged = pd.merge(df_a, df_b, on=['distance', 'p', 'N'], suffixes=('_a', '_b'))\n",
    "    merged['inv_N'] = 1 / merged['N']\n",
    "    merged['rel_diff'] = (merged['l_a'] - merged['l_b']) / (0.5 * (merged['l_a'] + merged['l_b']))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    distances = sorted(merged['distance'].unique())\n",
    "    colors = [\n",
    "        \"rgb(255,0,0)\",    # red\n",
    "        \"rgb(0,128,0)\",    # green\n",
    "        \"rgb(0,0,255)\",    # blue\n",
    "    ]\n",
    "\n",
    "    for i, d in enumerate(distances):\n",
    "        df_d = merged[merged['distance'] == d]\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # --- near-zero filled region (|rel_diff| < eps) ---\n",
    "        band_points = []\n",
    "        for invN, group in df_d.groupby('inv_N'):\n",
    "            group = group.sort_values('p')\n",
    "            near = group[np.abs(group['rel_diff']) < eps]\n",
    "            if not near.empty:\n",
    "                band_points.append((invN, near['p'].min(), near['p'].max()))\n",
    "\n",
    "        if band_points:\n",
    "            band_points = np.array(sorted(band_points, key=lambda x: x[0]))\n",
    "            x = band_points[:, 0]\n",
    "            y_low = band_points[:, 1]\n",
    "            y_high = band_points[:, 2]\n",
    "            y_low = pd.Series(y_low).rolling(window=20, center=True, min_periods=1).mean().values\n",
    "            y_high = pd.Series(y_high).rolling(window=20, center=True, min_periods=1).mean().values\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=np.concatenate([x, x[::-1]]),\n",
    "                y=np.concatenate([y_high, y_low[::-1]]),\n",
    "                fill='toself',\n",
    "                fillcolor=color.replace('rgb', 'rgba').replace(')', ',0.15)'),  # ~15% opacity\n",
    "                line=dict(color='rgba(0,0,0,0)'),\n",
    "                hoverinfo='skip',\n",
    "                name=f\"d={d} ɛ={eps}\",\n",
    "                legendgroup=f\"d={d}\",\n",
    "                showlegend=False\n",
    "            ))\n",
    "\n",
    "        # --- threshold points (zero crossing) ---\n",
    "        thresholds = []\n",
    "        for invN, group in df_d.groupby('inv_N'):\n",
    "            group = group.sort_values('p')\n",
    "            sign = np.sign(group['rel_diff'].values)\n",
    "            change_indices = np.where(np.diff(sign))[0]\n",
    "            if len(change_indices) > 0:\n",
    "                i0 = change_indices[0]\n",
    "                p1, p2 = group['p'].iloc[i0], group['p'].iloc[i0 + 1]\n",
    "                y1, y2 = group['rel_diff'].iloc[i0], group['rel_diff'].iloc[i0 + 1]\n",
    "                p_thresh = p1 - y1 * (p2 - p1) / (y2 - y1)\n",
    "                thresholds.append((invN, p_thresh))\n",
    "\n",
    "        if thresholds:\n",
    "            thresholds = np.array(sorted(thresholds, key=lambda t: t[0]))\n",
    "            x = thresholds[:, 0].astype(float)\n",
    "            y = thresholds[:, 1].astype(float)\n",
    "\n",
    "            # --- raw dashed threshold line ---\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x,\n",
    "                y=y,\n",
    "                mode='lines',\n",
    "                line=dict(color=color, width=1, dash='dash'),\n",
    "                name=f\"d={d} (raw)\",\n",
    "                legendgroup=f\"d={d}\",\n",
    "                showlegend=False,\n",
    "            ))\n",
    "\n",
    "            # --- smooth line (rolling average) ---\n",
    "            window = min(20, max(3, int(len(y) / 5)))\n",
    "            y_smooth = pd.Series(y).rolling(window=window, center=True, min_periods=1).mean().values\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x,\n",
    "                y=y_smooth,\n",
    "                mode='lines',\n",
    "                line=dict(color=color, width=3, shape='spline'),\n",
    "                name=f\"d={d}\",\n",
    "                legendgroup=f\"d={d}\",\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Threshold comparison: {decoder_a} vs {decoder_b}\",\n",
    "        xaxis_title=\"1/N\",\n",
    "        yaxis_title=\"p (threshold where rel_diff≈0)\",\n",
    "        height=650,\n",
    "        template=\"plotly_white\",\n",
    "        legend_title=\"Distance\",\n",
    "    )\n",
    "\n",
    "    return Plot(fig, f\"Threshold comparison: {decoder_a} vs {decoder_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b632512",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dirs = [\n",
    "    \"../data/ccluster/results_idling_d6\",\n",
    "]\n",
    "\n",
    "data = collect_data(base_dirs, [])\n",
    "# group by decoder, p and N, take mean of l\n",
    "data_mean = data.results.groupby(['decoder', 'distance', 'N', 'p'], dropna=False).mean().reset_index()\n",
    "\n",
    "# Choose all lines where N is NaN or 1/N <= 0.05\n",
    "data_mean = data_mean[(data_mean['N'].isna()) | (1.0/data_mean['N'] <= 0.005)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50a7cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = idling_threshold_plots(data_mean, 'uf', 'clayg', display_thresholds=True)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3939e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 12:43:48.718: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n"
     ]
    }
   ],
   "source": [
    "plot = idling_threshold_comparison_plot(data_mean, 'uf', 'clayg', eps=0.1)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790cb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_plot(results) -> Plot:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    distances = set()\n",
    "    \n",
    "    for (decoder, distance), values in results.items():\n",
    "        distances.add(distance)\n",
    "        colors = decoder_colors.get(decoder, decoder_colors['other'])\n",
    "        decoder_name = decoder_names.get(decoder, decoder)\n",
    "        ps = list(values.keys())\n",
    "        ls, ns = zip(*(values.values()))\n",
    "        ls = list(ls)\n",
    "        ns = list(ns)\n",
    "\n",
    "        sorted_indices = np.argsort(ps)\n",
    "        ps = np.array(ps)[sorted_indices]\n",
    "        ls = np.array(ls)[sorted_indices]\n",
    "        \n",
    "        # Compute Wilson score uncertainties\n",
    "        # phat is the estimated proportion of failures\n",
    "        z = norm.ppf(1 - 0.05 / 2)  # for 95% confidence\n",
    "        ns = [n if not n == None and not np.isnan(n) else 200000 for n in ns]\n",
    "        sigma = [1 / (1 + z**2 / n) * (l + z/(2*n)*(z + np.sqrt(4*n*l*(1-l))+z**2)) for l, n in zip(ls, ns)]\n",
    "        sigma = np.array(sigma)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=ps,\n",
    "            y=ls,\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=sigma,\n",
    "                visible=False,\n",
    "                thickness=1.5,\n",
    "                width=3\n",
    "            ),\n",
    "            mode='lines+markers',\n",
    "            name=f\"{decoder_name} d={distance}\",\n",
    "            line=dict(color=colors[distance % len(colors)], width=2),\n",
    "            marker=dict(size=5),\n",
    "            legendgroup=decoder_name,\n",
    "            legendgrouptitle_text=decoder_name,\n",
    "            hovertemplate=f\"{decoder_name} d={distance}<br>p: %{{x:.2e}}<br>L: %{{y:.2e}}\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "                \n",
    "\n",
    "        if len(ps) < 2:\n",
    "            print(f\"Not enough data points for fitting for {decoder_name} d={distance}\")\n",
    "            continue\n",
    "\n",
    "        def power_law(x, a, b):\n",
    "            return a * np.power(x, b)\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(\n",
    "                power_law, ps, ls, sigma=sigma, absolute_sigma=True\n",
    "            )\n",
    "            a, b = popt\n",
    "            print(f\"{decoder_name} d={distance}, d/2={(distance)/2}, b={b:.4f}\")\n",
    "            fit_x = np.linspace(min(ps), max(ps), 100)\n",
    "            fit_y = power_law(fit_x, *popt)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=fit_x,\n",
    "                y=fit_y,\n",
    "                mode='lines',\n",
    "                name=f\"{decoder_name} fit d={distance}\",\n",
    "                line=dict(color=colors[distance % len(colors)], width=1, dash='dash'),\n",
    "                legendgroup=f\"{decoder_name} fit\",\n",
    "                legendgrouptitle_text=f\"{decoder_name} fit\",\n",
    "                hovertemplate=f\"{decoder_name} fit d={distance}: <br> parameters: c={b:.4f}<br> d/2={(distance)/2}\",\n",
    "                showlegend=True,\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting data for {decoder_name} d={distance}: {e}\")\n",
    "    \n",
    "    # Set legend groups ending with fit to not selected by default\n",
    "    for trace in fig.data:\n",
    "        if 'fit' in trace.name:\n",
    "            trace.visible = 'legendonly'\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Results\",\n",
    "        legend_title=\"Decoder\",\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(type='log', title='p (log scale)'),\n",
    "        yaxis=dict(type='log', title='L (log scale)'),\n",
    "    )\n",
    "    \n",
    "    return Plot(fig, \"Threshold Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced0168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7023/2996896351.py:6: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  results = data.results.groupby(['decoder', 'distance']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clayg_lifetime_0.0 d=6, d/2=3.0, b=2.8883\n",
      "clayg_lifetime_0.0 d=8, d/2=4.0, b=3.5399\n",
      "clayg_lifetime_0.0 d=10, d/2=5.0, b=3.9664\n",
      "clayg_lifetime_0.0 d=12, d/2=6.0, b=4.3972\n",
      "clayg_lifetime_0.0 d=14, d/2=7.0, b=4.6170\n",
      "clayg_lifetime_0.0 d=16, d/2=8.0, b=5.0506\n",
      "clayg_lifetime_0.25 d=6, d/2=3.0, b=2.8883\n",
      "clayg_lifetime_0.25 d=8, d/2=4.0, b=3.7604\n",
      "clayg_lifetime_0.25 d=10, d/2=5.0, b=4.3626\n",
      "clayg_lifetime_0.25 d=12, d/2=6.0, b=5.0272\n",
      "clayg_lifetime_0.25 d=14, d/2=7.0, b=5.5669\n",
      "clayg_lifetime_0.25 d=16, d/2=8.0, b=6.1331\n",
      "clayg_lifetime_0.5 d=6, d/2=3.0, b=3.0518\n",
      "clayg_lifetime_0.5 d=8, d/2=4.0, b=3.8243\n",
      "clayg_lifetime_0.5 d=10, d/2=5.0, b=4.5583\n",
      "clayg_lifetime_0.5 d=12, d/2=6.0, b=5.1197\n",
      "clayg_lifetime_0.5 d=14, d/2=7.0, b=5.7101\n",
      "clayg_lifetime_0.5 d=16, d/2=8.0, b=6.3825\n",
      "clayg_lifetime_0.75 d=6, d/2=3.0, b=3.0403\n",
      "clayg_lifetime_0.75 d=8, d/2=4.0, b=3.9240\n",
      "clayg_lifetime_0.75 d=10, d/2=5.0, b=4.6447\n",
      "clayg_lifetime_0.75 d=12, d/2=6.0, b=5.3838\n",
      "clayg_lifetime_0.75 d=14, d/2=7.0, b=6.0080\n",
      "clayg_lifetime_0.75 d=16, d/2=8.0, b=6.6535\n",
      "clayg_lifetime_1.0 d=6, d/2=3.0, b=3.1073\n",
      "clayg_lifetime_1.0 d=8, d/2=4.0, b=4.0418\n",
      "clayg_lifetime_1.0 d=10, d/2=5.0, b=4.8637\n",
      "clayg_lifetime_1.0 d=12, d/2=6.0, b=5.5846\n",
      "clayg_lifetime_1.0 d=14, d/2=7.0, b=6.4376\n",
      "clayg_lifetime_1.0 d=16, d/2=8.0, b=6.7519\n",
      "UF d=6, d/2=3.0, b=3.2242\n",
      "UF d=8, d/2=4.0, b=4.7683\n",
      "UF d=10, d/2=5.0, b=5.3451\n",
      "UF d=12, d/2=6.0, b=6.3441\n",
      "UF d=14, d/2=7.0, b=7.0329\n",
      "UF d=16, d/2=8.0, b=7.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 10:10:38.039: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n"
     ]
    }
   ],
   "source": [
    "base_dirs = [\n",
    "    \"../data/ccluster/test_cluster_lifetime/results_test_cluster_lifetime/\",\n",
    "]\n",
    "\n",
    "data = collect_data(base_dirs, [])\n",
    "results = data.results.groupby(['decoder', 'distance']).apply(\n",
    "    lambda x: x.set_index('p')[['l', 'n']].apply(lambda row: (row['l'], row['n']), axis=1).to_dict()\n",
    ").to_dict()\n",
    "threshold_plot(results).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327fe53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7023/3751099052.py:8: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "/tmp/ipykernel_7023/3751099052.py:19: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "/tmp/ipykernel_7023/3751099052.py:41: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting None p=0.001, data points: 6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     52\u001b[39m average_steps_by_p = (\n\u001b[32m     53\u001b[39m     avg_steps\n\u001b[32m     54\u001b[39m     .pivot_table(index=[\u001b[33m'\u001b[39m\u001b[33mdecoder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m], columns=\u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m, values=\u001b[33m'\u001b[39m\u001b[33mavg_steps\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     55\u001b[39m     .apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row.dropna().to_dict(), axis=\u001b[32m1\u001b[39m)\n\u001b[32m     56\u001b[39m     .to_dict()\n\u001b[32m     57\u001b[39m )\n\u001b[32m     60\u001b[39m plot_step_distribution_by_p(steps).show()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m average_plot = \u001b[43mplot_operations_against_d\u001b[49m\u001b[43m(\u001b[49m\u001b[43maverage_steps_by_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m average_plot.set_title(\u001b[33m\"\u001b[39m\u001b[33mAverage Operations against d, grouped by p\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m average_plot.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mplot_operations_against_d\u001b[39m\u001b[34m(average_operations)\u001b[39m\n\u001b[32m     47\u001b[39m     y = np.array(y)[sorted_indices]\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlotting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m p=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, data points: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     fig.add_trace(go.Scatter(\n\u001b[32m     50\u001b[39m         x=x,\n\u001b[32m     51\u001b[39m         y=y,\n\u001b[32m     52\u001b[39m         mode=\u001b[33m'\u001b[39m\u001b[33mlines+markers\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     53\u001b[39m         name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m p=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         line=\u001b[38;5;28mdict\u001b[39m(color=colors[\u001b[38;5;28mint\u001b[39m(p*\u001b[32m1000\u001b[39m) % \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m], width=\u001b[32m2\u001b[39m),\n\u001b[32m     55\u001b[39m         marker=\u001b[38;5;28mdict\u001b[39m(size=\u001b[32m5\u001b[39m),\n\u001b[32m     56\u001b[39m         legendgroup=decoder,\n\u001b[32m     57\u001b[39m         legendgrouptitle_text=decoder,\n\u001b[32m     58\u001b[39m         hovertemplate=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m p=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m<br>d: %\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33mx\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m<br>avg. # of operations: %\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33my:.3\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     59\u001b[39m         showlegend=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     60\u001b[39m     ))\n\u001b[32m     62\u001b[39m fig.update_layout(\n\u001b[32m     63\u001b[39m     legend_title=\u001b[33m\"\u001b[39m\u001b[33mDecoder\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     64\u001b[39m     template=\u001b[33m\"\u001b[39m\u001b[33mplotly_white\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m     xaxis=\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, title=\u001b[33m'\u001b[39m\u001b[33mdistance d (linear scale)\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     66\u001b[39m     yaxis=\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, title=\u001b[33m'\u001b[39m\u001b[33mOperations (linear scale)\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     67\u001b[39m )\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Plot(fig, \u001b[33m\"\u001b[39m\u001b[33mOperations against d, grouped by p\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 16:57:55.739: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n"
     ]
    }
   ],
   "source": [
    "# Plot average and median operations grouped by distance and p\n",
    "base_dirs = [\n",
    "    \"../data/ccluster/test_cluster_lifetime/results_test_cluster_lifetime\",\n",
    "]\n",
    "\n",
    "data = collect_data(base_dirs, [])\n",
    "\n",
    "steps = data.steps.groupby(['decoder', 'distance', 'p']).apply(lambda x: x.set_index('value')['occurences'].to_dict()).to_dict()\n",
    "\n",
    "def weighted_median(df):\n",
    "    expanded = []\n",
    "    for value, count in zip(df['value'], df['occurences']):\n",
    "        expanded.extend([value] * count)\n",
    "    return np.median(expanded)\n",
    "\n",
    "median_steps = (\n",
    "    data.steps\n",
    "    .groupby(['decoder', 'distance', 'p'])\n",
    "    .apply(weighted_median)\n",
    "    .reset_index(name='avg_steps')\n",
    ")\n",
    "\n",
    "median_steps_by_d = (\n",
    "    median_steps\n",
    "    .pivot_table(index=['decoder', 'p'], columns='distance', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "median_steps_by_p = (\n",
    "    median_steps\n",
    "    .pivot_table(index=['decoder', 'distance'], columns='p', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "avg_steps = (\n",
    "    data.steps\n",
    "    .groupby(['decoder', 'distance', 'p'])\n",
    "    .apply(lambda x: np.average(x['value'], weights=x['occurences']))\n",
    "    .reset_index(name='avg_steps')\n",
    ")\n",
    "\n",
    "average_steps_by_d = (\n",
    "    avg_steps\n",
    "    .pivot_table(index=['decoder', 'p'], columns='distance', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "average_steps_by_p = (\n",
    "    avg_steps\n",
    "    .pivot_table(index=['decoder', 'distance'], columns='p', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "plot_step_distribution_by_p(steps).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f17ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting clayg_lifetime_0.0 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.03456, data points: 6\n",
      "Plotting UF p=0.001, data points: 6\n",
      "Plotting UF p=0.00128, data points: 6\n",
      "Plotting UF p=0.001638, data points: 6\n",
      "Plotting UF p=0.002097, data points: 6\n",
      "Plotting UF p=0.002684, data points: 6\n",
      "Plotting UF p=0.003436, data points: 6\n",
      "Plotting UF p=0.004398, data points: 6\n",
      "Plotting UF p=0.005629, data points: 6\n",
      "Plotting UF p=0.007206, data points: 6\n",
      "Plotting UF p=0.009223, data points: 6\n",
      "Plotting UF p=0.011806, data points: 6\n",
      "Plotting UF p=0.015112, data points: 6\n",
      "Plotting UF p=0.019343, data points: 6\n",
      "Plotting UF p=0.024, data points: 6\n",
      "Plotting UF p=0.0288, data points: 6\n",
      "Plotting UF p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.0 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=16, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=6, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=8, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=10, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=12, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=14, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=16, data points: 16\n",
      "Plotting UF d=6, data points: 16\n",
      "Plotting UF d=8, data points: 16\n",
      "Plotting UF d=10, data points: 16\n",
      "Plotting UF d=12, data points: 16\n",
      "Plotting UF d=14, data points: 16\n",
      "Plotting UF d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.0 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.0 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.25 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.5 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_0.75 p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.001, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.00128, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.001638, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.002097, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.002684, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.003436, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.004398, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.005629, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.007206, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.009223, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.011806, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.015112, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.019343, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.024, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.0288, data points: 6\n",
      "Plotting clayg_lifetime_1.0 p=0.03456, data points: 6\n",
      "Plotting UF p=0.001, data points: 6\n",
      "Plotting UF p=0.00128, data points: 6\n",
      "Plotting UF p=0.001638, data points: 6\n",
      "Plotting UF p=0.002097, data points: 6\n",
      "Plotting UF p=0.002684, data points: 6\n",
      "Plotting UF p=0.003436, data points: 6\n",
      "Plotting UF p=0.004398, data points: 6\n",
      "Plotting UF p=0.005629, data points: 6\n",
      "Plotting UF p=0.007206, data points: 6\n",
      "Plotting UF p=0.009223, data points: 6\n",
      "Plotting UF p=0.011806, data points: 6\n",
      "Plotting UF p=0.015112, data points: 6\n",
      "Plotting UF p=0.019343, data points: 6\n",
      "Plotting UF p=0.024, data points: 6\n",
      "Plotting UF p=0.0288, data points: 6\n",
      "Plotting UF p=0.03456, data points: 6\n",
      "Plotting clayg_lifetime_0.0 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.0 d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.25 d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.5 d=16, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=6, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=8, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=10, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=12, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=14, data points: 16\n",
      "Plotting clayg_lifetime_0.75 d=16, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=6, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=8, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=10, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=12, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=14, data points: 16\n",
      "Plotting clayg_lifetime_1.0 d=16, data points: 16\n",
      "Plotting UF d=6, data points: 16\n",
      "Plotting UF d=8, data points: 16\n",
      "Plotting UF d=10, data points: 16\n",
      "Plotting UF d=12, data points: 16\n",
      "Plotting UF d=14, data points: 16\n",
      "Plotting UF d=16, data points: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 17:00:43.584: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 17:00:43.664: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n",
      "Gtk-Message: 17:00:43.858: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n",
      "Gtk-Message: 17:00:43.887: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n"
     ]
    }
   ],
   "source": [
    "average_plot = plot_operations_against_d(average_steps_by_d)\n",
    "average_plot.set_title(\"Average Operations against d, grouped by p\")\n",
    "average_plot.show()\n",
    "\n",
    "average_plot = plot_operations_against_p(average_steps_by_p)\n",
    "average_plot.set_title(\"Average Operations against p, grouped by d\")\n",
    "average_plot.show()\n",
    "\n",
    "\n",
    "median_plot = plot_operations_against_d(median_steps_by_d)\n",
    "median_plot.set_title(\"Median Operations against d, grouped by p\")\n",
    "median_plot.show()\n",
    "\n",
    "median_plot = plot_operations_against_p(median_steps_by_p)\n",
    "median_plot.set_title(\"Median Operations against p, grouped by d\")\n",
    "median_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb5904e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "decoder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distance",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "occurences",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1fed136a-2ad9-4b75-a498-5da77df44605",
       "rows": [
        [
         "0",
         "clayg_lifetime_0.0",
         "10",
         "0.001",
         "0.0",
         "84530"
        ],
        [
         "1",
         "clayg_lifetime_0.0",
         "10",
         "0.001",
         "1.0",
         "14136"
        ],
        [
         "2",
         "clayg_lifetime_0.0",
         "10",
         "0.001",
         "2.0",
         "1310"
        ],
        [
         "3",
         "clayg_lifetime_0.0",
         "10",
         "0.001",
         "3.0",
         "16"
        ],
        [
         "4",
         "clayg_lifetime_0.0",
         "10",
         "0.001",
         "4.0",
         "8"
        ],
        [
         "5",
         "clayg_lifetime_0.0",
         "10",
         "0.00128",
         "0.0",
         "80809"
        ],
        [
         "6",
         "clayg_lifetime_0.0",
         "10",
         "0.00128",
         "1.0",
         "17488"
        ],
        [
         "7",
         "clayg_lifetime_0.0",
         "10",
         "0.00128",
         "2.0",
         "1671"
        ],
        [
         "8",
         "clayg_lifetime_0.0",
         "10",
         "0.00128",
         "3.0",
         "19"
        ],
        [
         "9",
         "clayg_lifetime_0.0",
         "10",
         "0.00128",
         "4.0",
         "12"
        ],
        [
         "10",
         "clayg_lifetime_0.0",
         "10",
         "0.00128",
         "7.0",
         "1"
        ],
        [
         "11",
         "clayg_lifetime_0.0",
         "10",
         "0.001638",
         "0.0",
         "75745"
        ],
        [
         "12",
         "clayg_lifetime_0.0",
         "10",
         "0.001638",
         "1.0",
         "22083"
        ],
        [
         "13",
         "clayg_lifetime_0.0",
         "10",
         "0.001638",
         "2.0",
         "2118"
        ],
        [
         "14",
         "clayg_lifetime_0.0",
         "10",
         "0.001638",
         "3.0",
         "40"
        ],
        [
         "15",
         "clayg_lifetime_0.0",
         "10",
         "0.001638",
         "4.0",
         "14"
        ],
        [
         "16",
         "clayg_lifetime_0.0",
         "10",
         "0.002097",
         "0.0",
         "69977"
        ],
        [
         "17",
         "clayg_lifetime_0.0",
         "10",
         "0.002097",
         "1.0",
         "27122"
        ],
        [
         "18",
         "clayg_lifetime_0.0",
         "10",
         "0.002097",
         "2.0",
         "2820"
        ],
        [
         "19",
         "clayg_lifetime_0.0",
         "10",
         "0.002097",
         "3.0",
         "45"
        ],
        [
         "20",
         "clayg_lifetime_0.0",
         "10",
         "0.002097",
         "4.0",
         "31"
        ],
        [
         "21",
         "clayg_lifetime_0.0",
         "10",
         "0.002097",
         "5.0",
         "5"
        ],
        [
         "22",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "0.0",
         "63528"
        ],
        [
         "23",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "1.0",
         "32631"
        ],
        [
         "24",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "2.0",
         "3701"
        ],
        [
         "25",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "3.0",
         "85"
        ],
        [
         "26",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "4.0",
         "41"
        ],
        [
         "27",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "5.0",
         "8"
        ],
        [
         "28",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "6.0",
         "5"
        ],
        [
         "29",
         "clayg_lifetime_0.0",
         "10",
         "0.002684",
         "7.0",
         "1"
        ],
        [
         "30",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "0.0",
         "56009"
        ],
        [
         "31",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "1.0",
         "38891"
        ],
        [
         "32",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "2.0",
         "4814"
        ],
        [
         "33",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "3.0",
         "155"
        ],
        [
         "34",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "4.0",
         "110"
        ],
        [
         "35",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "5.0",
         "7"
        ],
        [
         "36",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "6.0",
         "7"
        ],
        [
         "37",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "7.0",
         "5"
        ],
        [
         "38",
         "clayg_lifetime_0.0",
         "10",
         "0.003436",
         "8.0",
         "2"
        ],
        [
         "39",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "0.0",
         "47305"
        ],
        [
         "40",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "1.0",
         "45446"
        ],
        [
         "41",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "2.0",
         "6778"
        ],
        [
         "42",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "3.0",
         "246"
        ],
        [
         "43",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "4.0",
         "172"
        ],
        [
         "44",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "5.0",
         "19"
        ],
        [
         "45",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "6.0",
         "12"
        ],
        [
         "46",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "7.0",
         "14"
        ],
        [
         "47",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "8.0",
         "7"
        ],
        [
         "48",
         "clayg_lifetime_0.0",
         "10",
         "0.004398",
         "9.0",
         "1"
        ],
        [
         "49",
         "clayg_lifetime_0.0",
         "10",
         "0.005629",
         "0.0",
         "37684"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4382
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder</th>\n",
       "      <th>distance</th>\n",
       "      <th>p</th>\n",
       "      <th>value</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clayg_lifetime_0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clayg_lifetime_0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clayg_lifetime_0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clayg_lifetime_0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clayg_lifetime_0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>uf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.03456</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>uf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.03456</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>uf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.03456</td>\n",
       "      <td>6.0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>uf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.03456</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>uf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.03456</td>\n",
       "      <td>9.0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4382 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 decoder  distance        p  value  occurences\n",
       "0     clayg_lifetime_0.0        10  0.00100    0.0       84530\n",
       "1     clayg_lifetime_0.0        10  0.00100    1.0       14136\n",
       "2     clayg_lifetime_0.0        10  0.00100    2.0        1310\n",
       "3     clayg_lifetime_0.0        10  0.00100    3.0          16\n",
       "4     clayg_lifetime_0.0        10  0.00100    4.0           8\n",
       "...                  ...       ...      ...    ...         ...\n",
       "4377                  uf        14  0.03456    4.0       15671\n",
       "4378                  uf        14  0.03456    5.0       67854\n",
       "4379                  uf        14  0.03456    6.0         117\n",
       "4380                  uf        14  0.03456    7.0        4706\n",
       "4381                  uf        14  0.03456    9.0          62\n",
       "\n",
       "[4382 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdfda749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_operations_against_p(average_operations) -> Plot:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for (decoder, distance), values in average_operations.items():\n",
    "        colors = decoder_colors.get(decoder, decoder_colors['other'])\n",
    "        decoder_name = decoder_names.get(decoder, decoder)\n",
    "        x = list(values.keys())\n",
    "        y = list(values.values())\n",
    "        # sort by x\n",
    "        sorted_indices = np.argsort(x)\n",
    "        x = np.array(x)[sorted_indices]\n",
    "        y = np.array(y)[sorted_indices]\n",
    "        print(f\"Plotting {decoder_name} d={distance}, data points: {len(x)}\")\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='lines+markers',\n",
    "            name=f\"{decoder_name} d={distance}\",\n",
    "            line=dict(color=colors[distance % len(colors)], width=2),\n",
    "            marker=dict(size=5),\n",
    "            legendgroup=decoder_name,\n",
    "            legendgrouptitle_text=decoder_name,\n",
    "            hovertemplate=f\"{decoder_name} d={distance}<br>p: %{{x:.2e}}<br>avg. # of operations: %{{y:.3}}\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend_title=\"Decoder\",\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(type='linear', title='p (linear scale)'),\n",
    "        yaxis=dict(type='linear', title='Operations (linear scale)'),\n",
    "    )\n",
    "    \n",
    "    return Plot(fig, \"Operations against p, grouped by distance\")\n",
    "\n",
    "def plot_operations_against_d(average_operations) -> Plot:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for (decoder, p), values in average_operations.items():\n",
    "        colors = decoder_colors.get(decoder, decoder_colors['other'])\n",
    "        decoder = decoder_names.get(decoder, decoder)\n",
    "        x = list(values.keys())\n",
    "        y = list(values.values())\n",
    "        # sort by x\n",
    "        sorted_indices = np.argsort(x)\n",
    "        x = np.array(x)[sorted_indices]\n",
    "        y = np.array(y)[sorted_indices]\n",
    "        print(f\"Plotting {decoder} p={p}, data points: {len(x)}\")\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='lines+markers',\n",
    "            name=f\"{decoder} p={p}\",\n",
    "            line=dict(color=colors[int(p*1000) % len(colors)], width=2),\n",
    "            marker=dict(size=5),\n",
    "            legendgroup=decoder,\n",
    "            legendgrouptitle_text=decoder,\n",
    "            hovertemplate=f\"{decoder} p={p}<br>d: %{{x}}<br>avg. # of operations: %{{y:.3}}\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend_title=\"Decoder\",\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(type='linear', title='distance d (linear scale)'),\n",
    "        yaxis=dict(type='linear', title='Operations (linear scale)'),\n",
    "    )\n",
    "    \n",
    "    return Plot(fig, \"Operations against d, grouped by p\")\n",
    "\n",
    "def plot_step_distribution_by_p(steps) -> Plot:\n",
    "    # Get all unique p values\n",
    "    ps = set(p for (_, _, p) in steps.keys())\n",
    "    if len(ps) > 1:\n",
    "        # Multiple p: group by (decoder, distance), columns for each p\n",
    "        group = defaultdict(list)\n",
    "        for decoder, distance, p in steps.keys():\n",
    "            group[(decoder, distance)].append(p)\n",
    "        row_keys = list(group.keys())\n",
    "        max_cols = max(len(ps) for ps in group.values())\n",
    "        fig = make_subplots(\n",
    "            rows=len(row_keys), cols=max_cols,\n",
    "            subplot_titles=[\n",
    "                f\"{decoder_names.get(decoder, decoder)} d={distance}, p={p:.1e}\" if p is not None else \"\"\n",
    "                for (decoder, distance), ps in group.items() for p in (sorted(ps) if len(ps) == max_cols else sorted(ps) + [None] * (max_cols - len(ps)))\n",
    "            ],\n",
    "        )\n",
    "        for row, (decoder, distance) in enumerate(row_keys, start=1):\n",
    "            ps_sorted = sorted(group[(decoder, distance)])\n",
    "            for col, p in enumerate(ps_sorted, start=1):\n",
    "                values = steps[(decoder, distance, p)]\n",
    "                x = []\n",
    "                for step_val, count in sorted(values.items()):\n",
    "                    x.extend([step_val] * count)\n",
    "                colors = decoder_colors.get(decoder, decoder_colors['other'])\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=x,\n",
    "                        marker_color=colors[distance % len(colors)],\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "    else:\n",
    "        # Only one p: group by decoder, columns for each distance\n",
    "        group = defaultdict(list)\n",
    "        for decoder, distance, p in steps.keys():\n",
    "            group[decoder].append(distance)\n",
    "        row_keys = list(group.keys())\n",
    "        max_cols = max(len(ds) for ds in group.values())\n",
    "        fig = make_subplots(\n",
    "            rows=len(row_keys), cols=max_cols,\n",
    "            subplot_titles=[\n",
    "                f\"{decoder_names.get(decoder, decoder)} d={distance}\" if distance is not None else \"\"\n",
    "                for decoder, ds in group.items() for distance in (sorted(ds) if len(ds) == max_cols else sorted(ds)+ [None]*(max_cols - len(ds)))\n",
    "            ],\n",
    "        )\n",
    "        for row, decoder in enumerate(row_keys, start=1):\n",
    "            ds_sorted = sorted(group[decoder])\n",
    "            for col, distance in enumerate(ds_sorted, start=1):\n",
    "                # Since only one p, get it\n",
    "                p = next(p for (d, dep, p) in steps.keys() if d == decoder and dep == distance)\n",
    "                values = steps[(decoder, distance, p)]\n",
    "                x = []\n",
    "                for step_val, count in sorted(values.items()):\n",
    "                    x.extend([step_val] * count)\n",
    "                colors = decoder_colors.get(decoder)\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=x,\n",
    "                        marker_color=colors[distance % len(colors)],\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "    fig.update_layout(\n",
    "        template=\"plotly_white\",\n",
    "        height=300 * len(row_keys),\n",
    "        width=500 * max_cols\n",
    "    )\n",
    "    for i in range(1, len(row_keys) + 1):\n",
    "        fig.update_yaxes(title_text=\"Count\", row=i, col=1)\n",
    "    for j in range(1, max_cols + 1):\n",
    "        fig.update_xaxes(title_text=\"Steps\", row=1, col=j)\n",
    "    \n",
    "    return Plot(fig, \"Step Distribution by Decoder, Distance, and p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7023/1399334739.py:7: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "/tmp/ipykernel_7023/1399334739.py:18: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "/tmp/ipykernel_7023/1399334739.py:40: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_step_distribution_by_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     44\u001b[39m average_steps_by_d = (\n\u001b[32m     45\u001b[39m     avg_steps\n\u001b[32m     46\u001b[39m     .pivot_table(index=[\u001b[33m'\u001b[39m\u001b[33mdecoder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m], columns=\u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m, values=\u001b[33m'\u001b[39m\u001b[33mavg_steps\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     47\u001b[39m     .apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row.dropna().to_dict(), axis=\u001b[32m1\u001b[39m)\n\u001b[32m     48\u001b[39m     .to_dict()\n\u001b[32m     49\u001b[39m )\n\u001b[32m     51\u001b[39m average_steps_by_p = (\n\u001b[32m     52\u001b[39m     avg_steps\n\u001b[32m     53\u001b[39m     .pivot_table(index=[\u001b[33m'\u001b[39m\u001b[33mdecoder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m], columns=\u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m, values=\u001b[33m'\u001b[39m\u001b[33mavg_steps\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     54\u001b[39m     .apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row.dropna().to_dict(), axis=\u001b[32m1\u001b[39m)\n\u001b[32m     55\u001b[39m     .to_dict()\n\u001b[32m     56\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mplot_step_distribution_by_p\u001b[49m(steps).show()\n\u001b[32m     61\u001b[39m average_plot = plot_operations_against_d(average_steps_by_d)\n\u001b[32m     62\u001b[39m average_plot.set_title(\u001b[33m\"\u001b[39m\u001b[33mAverage Operations against d, grouped by p\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plot_step_distribution_by_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot average and median operations grouped by distance and p\n",
    "base_dirs = [\n",
    "    \"../data/ccluster/steps_new\",\n",
    "]\n",
    "\n",
    "data = collect_data(base_dirs, [])\n",
    "\n",
    "steps = data.steps.groupby(['decoder', 'distance', 'p']).apply(lambda x: x.set_index('value')['occurences'].to_dict()).to_dict()\n",
    "\n",
    "def weighted_median(df):\n",
    "    expanded = []\n",
    "    for value, count in zip(df['value'], df['occurences']):\n",
    "        expanded.extend([value] * count)\n",
    "    return np.median(expanded)\n",
    "\n",
    "median_steps = (\n",
    "    data.steps\n",
    "    .groupby(['decoder', 'distance', 'p'])\n",
    "    .apply(weighted_median)\n",
    "    .reset_index(name='avg_steps')\n",
    ")\n",
    "\n",
    "median_steps_by_d = (\n",
    "    median_steps\n",
    "    .pivot_table(index=['decoder', 'p'], columns='distance', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "median_steps_by_p = (\n",
    "    median_steps\n",
    "    .pivot_table(index=['decoder', 'distance'], columns='p', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "avg_steps = (\n",
    "    data.steps\n",
    "    .groupby(['decoder', 'distance', 'p'])\n",
    "    .apply(lambda x: np.average(x['value'], weights=x['occurences']))\n",
    "    .reset_index(name='avg_steps')\n",
    ")\n",
    "\n",
    "average_steps_by_d = (\n",
    "    avg_steps\n",
    "    .pivot_table(index=['decoder', 'p'], columns='distance', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "average_steps_by_p = (\n",
    "    avg_steps\n",
    "    .pivot_table(index=['decoder', 'distance'], columns='p', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "plot_step_distribution_by_p(steps).show()\n",
    "\n",
    "average_plot = plot_operations_against_d(average_steps_by_d)\n",
    "average_plot.set_title(\"Average Operations against d, grouped by p\")\n",
    "average_plot.show()\n",
    "\n",
    "average_plot = plot_operations_against_p(average_steps_by_p)\n",
    "average_plot.set_title(\"Average Operations against p, grouped by d\")\n",
    "average_plot.show()\n",
    "\n",
    "\n",
    "median_plot = plot_operations_against_d(median_steps_by_d)\n",
    "median_plot.set_title(\"Median Operations against d, grouped by p\")\n",
    "median_plot.show()\n",
    "\n",
    "median_plot = plot_operations_against_p(median_steps_by_p)\n",
    "median_plot.set_title(\"Median Operations against p, grouped by d\")\n",
    "median_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c456e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClAYG d=6, d/2=3.0, b=2.8623\n",
      "ClAYG d=8, d/2=4.0, b=3.5901\n",
      "ClAYG d=10, d/2=5.0, b=4.0491\n",
      "ClAYG d=12, d/2=6.0, b=4.3566\n",
      "ClAYG d=14, d/2=7.0, b=4.5684\n",
      "ClAYG d=16, d/2=8.0, b=5.2777\n",
      "ClAYG Stop Early d=6, d/2=3.0, b=2.8657\n",
      "ClAYG Stop Early d=8, d/2=4.0, b=3.2075\n",
      "ClAYG Stop Early d=10, d/2=5.0, b=3.4306\n",
      "ClAYG Stop Early d=12, d/2=6.0, b=3.5557\n",
      "ClAYG Stop Early d=14, d/2=7.0, b=3.6406\n",
      "ClAYG Stop Early d=16, d/2=8.0, b=3.6499\n",
      "Single Layer ClAYG d=6, d/2=3.0, b=2.7617\n",
      "Single Layer ClAYG d=8, d/2=4.0, b=3.3287\n",
      "Single Layer ClAYG d=10, d/2=5.0, b=3.4472\n",
      "Single Layer ClAYG d=12, d/2=6.0, b=3.6408\n",
      "Single Layer ClAYG d=14, d/2=7.0, b=3.6280\n",
      "Single Layer ClAYG d=16, d/2=8.0, b=3.7053\n",
      "Single Layer ClAYG Stop Early d=6, d/2=3.0, b=2.7767\n",
      "Single Layer ClAYG Stop Early d=8, d/2=4.0, b=3.0895\n",
      "Single Layer ClAYG Stop Early d=10, d/2=5.0, b=3.1983\n",
      "Single Layer ClAYG Stop Early d=12, d/2=6.0, b=3.2839\n",
      "Single Layer ClAYG Stop Early d=14, d/2=7.0, b=3.3253\n",
      "Single Layer ClAYG Stop Early d=16, d/2=8.0, b=3.2992\n",
      "UF d=6, d/2=3.0, b=3.2124\n",
      "UF d=8, d/2=4.0, b=4.4007\n",
      "UF d=10, d/2=5.0, b=5.3268\n",
      "UF d=12, d/2=6.0, b=6.3466\n",
      "UF d=14, d/2=7.0, b=6.8602\n",
      "UF d=16, d/2=8.0, b=7.9574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5497/1213777410.py:6: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 16:09:50.609: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n"
     ]
    }
   ],
   "source": [
    "# Threshold plots for new peeling decoder\n",
    "base_dirs = [\n",
    "    \"../data/ccluster/results_new_peeling\",\n",
    "]\n",
    "\n",
    "data = collect_data(base_dirs, [])\n",
    "results = data.results.groupby(['decoder', 'distance']).apply(\n",
    "    lambda x: x.set_index('p')[['l', 'n']].apply(lambda row: (row['l'], row['n']), axis=1).to_dict()\n",
    ").to_dict()\n",
    "threshold_plot(results).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for the tests with different growth rates\n",
    "base_dir = \"data/old/special_clayg_tests\"\n",
    "average_operations = collect_data_old(base_dir, [2])\n",
    "results = average_operations.loc[(average_operations['metric'] == 'results') & (average_operations['p'] > 0) & (average_operations['value'] > 0)].groupby(['decoder', 'distance']).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "\n",
    "\n",
    "fig = threshold_plot(results)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78544a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for the tests with clayg with faster backwards growth\n",
    "base_dir = \"data/old/special_clayg_grow_faster_backwards\"\n",
    "average_operations = collect_data_old(base_dir, [1])\n",
    "print(len(average_operations))\n",
    "average_operations = average_operations.loc[(average_operations['metric'] == 'results') & (average_operations['p'] > 0) & (average_operations['value'] > 0)]\n",
    "results = average_operations.groupby(['decoder', 'distance'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = threshold_plot(results)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for the tests with single layer clayg\n",
    "base_dir = \"data/old/single_layer_clayg_tests\"\n",
    "average_operations = collect_data_old(base_dir, [1,2,3])\n",
    "average_operations = average_operations.loc[(average_operations['metric'] == 'results') & (average_operations['p'] > 0) & (average_operations['value'] > 0)]\n",
    "results = average_operations.groupby(['decoder', 'distance'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = threshold_plot(results)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75452c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average operations against p\n",
    "base_dir = \"data/treshold_plots\"\n",
    "average_operations = collect_data_old(base_dir, [18,19,20,21, 22])\n",
    "average_operations = average_operations.loc[average_operations['metric'] == 'average_operations'].groupby(['decoder', 'distance'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = plot_operations_against_p(average_operations)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a506aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average operations against p\n",
    "base_dir = \"data/special_clayg_grow_faster_backwards\"\n",
    "average_operations = collect_data_old(base_dir, [1,2,3])\n",
    "average_operations = average_operations.loc[average_operations['metric'] == 'average_operations'].groupby(['decoder', 'distance'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = plot_operations_against_p(average_operations)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average operations against d\n",
    "base_dir = \"data/average_operations_initial\"\n",
    "data = collect_data_old(base_dir, [2,3])\n",
    "average_operations = data.loc[data['metric'] == 'average_operations'].groupby(['decoder', 'p'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('distance')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = plot_operations_against_d(average_operations)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

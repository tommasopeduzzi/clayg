{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a81c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "import os        \n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae22fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for plotting\n",
    "\n",
    "decoder_colors = {\n",
    "    'uf': [\n",
    "        \"#6baed6\", \"#4292c6\",\"#3182bd\", \"#1f77b4\", \"#2171b5\", \n",
    "        \"#08519c\", \"#08306b\", \"#08519c\", \"#08306b\", \"#08306b\",\n",
    "    ],\n",
    "    'clayg': [\n",
    "        \"#fdae6b\", \"#ffbb78\", \"#ff8c00\", \"#fd8d3c\", \"#ffa726\",\n",
    "        \"#f16913\", \"#ff7f0e\", \"#d95f02\", \"#d94801\", \"#a63603\",    \n",
    "    ],\n",
    "    'sl_clayg': [\n",
    "        \"#31a354\", \"#74c476\", \"#238b45\", \"#31a354\", \"#74c476\",\n",
    "        \"#006d2c\", \"#00441b\", \"#006d2c\", \"#00441b\", \"#006d2c\",\n",
    "    ],\n",
    "    'other': [\n",
    "        \"#e377c2\", \"#d62728\", \"#ff9896\", \"#c51b7d\", \"#8c564b\",\n",
    "        \"#e377c2\", \"#d62728\", \"#ff9896\", \"#c51b7d\", \"#8c564b\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "other_decoders = ['clayg_third_growth', 'clayg_faster_backwards_growth', 'sl_clayg_third_growth']\n",
    "for decoder in other_decoders:\n",
    "    decoder_colors[decoder] = decoder_colors['other']\n",
    "\n",
    "decoder_names = {\n",
    "    'uf': 'UF',\n",
    "    'clayg': 'ClAYG',\n",
    "    'sl_clayg': 'Single Layer ClAYG',\n",
    "    'clayg_third_growth': 'ClAYG ⅓ Growth',\n",
    "    'clayg_faster_backwards_growth': 'ClAYG w/ Faster Backwards Growth',\n",
    "    'sl_clayg_third_growth': 'Single Layer ClAYG ⅓ Growth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d50767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_old(base_dir, plot_ids):\n",
    "    data = pd.DataFrame(columns=[\"metric\", \"decoder\", \"depth\", \"p\", \"value\"])\n",
    "\n",
    "    for plot_id in plot_ids:\n",
    "        plot_folders = [f for f in glob.glob(os.path.join(base_dir, f\"{plot_id}-*\")) if os.path.isdir(f)]\n",
    "\n",
    "        if not plot_folders:\n",
    "            print(f\"No folders found for plot_id {plot_id}\")\n",
    "            continue\n",
    "        \n",
    "        folder = plot_folders[0]\n",
    "        files = glob.glob(os.path.join(folder, \"*.txt\"))\n",
    "\n",
    "        pattern = re.compile(r\"(average_operations|results)_(\\w+)_d=(\\d+)\\.txt\")\n",
    "        for file in files:\n",
    "            match = pattern.match(os.path.basename(file))\n",
    "            if not match:\n",
    "                continue\n",
    "            metric, decoder, depth = match.groups()\n",
    "            depth = int(depth)\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 2:\n",
    "                            key, value = parts\n",
    "                            # check if line is header or not\n",
    "                            if key == \"p\":\n",
    "                                continue\n",
    "                            try:\n",
    "                                p = float(key)\n",
    "                                value = float(value)\n",
    "                            except ValueError:\n",
    "                                print(f\"Skipping line with non-numeric key or value: {line.strip()}\")\n",
    "                                continue\n",
    "                            # add data to dataframe\n",
    "                            data.loc[len(data)] = {\n",
    "                                \"metric\": metric,\n",
    "                                \"decoder\": decoder,\n",
    "                                \"depth\": depth,\n",
    "                                \"p\": p,\n",
    "                                \"value\": value\n",
    "                            }\n",
    "    return data\n",
    "\n",
    "class Data:\n",
    "    results : pd.DataFrame\n",
    "    steps : pd.DataFrame\n",
    "\n",
    "def collect_data(base_dir, plot_ids):\n",
    "    data = Data()\n",
    "    data.results = pd.DataFrame(columns=[\"decoder\", \"depth\", \"p\", \"l\"])\n",
    "    data.steps = pd.DataFrame(columns=[\"decoder\", \"depth\", \"p\", \"value\", \"occurences\"])\n",
    "\n",
    "    for plot_id in plot_ids:\n",
    "        plot_folders = [f for f in glob.glob(os.path.join(base_dir, f\"{plot_id}-*\")) if os.path.isdir(f)]\n",
    "\n",
    "        if not plot_folders:\n",
    "            print(f\"No folders found for plot_id {plot_id}\")\n",
    "            continue\n",
    "        \n",
    "        folder = plot_folders[0]\n",
    "        results_files = glob.glob(os.path.join(folder, \"results\", \"*.txt\"))\n",
    "        steps_files = glob.glob(os.path.join(folder, \"steps\", \"*.txt\"))  \n",
    "        \n",
    "        results_file_pattern = re.compile(r\"(\\w+)_d=(\\d+)\\.txt\")\n",
    "        for file in results_files:\n",
    "            results_match = results_file_pattern.match(os.path.basename(file))\n",
    "            if not results_match:\n",
    "                continue\n",
    "            decoder, depth = results_match.groups()\n",
    "            depth = int(depth)\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 2:\n",
    "                            key, value = parts\n",
    "                            # check if line is header or not\n",
    "                            if key == \"p\":\n",
    "                                continue\n",
    "                            try:\n",
    "                                p = float(key)\n",
    "                                value = float(value)\n",
    "                            except ValueError:\n",
    "                                print(f\"Skipping line with non-numeric key or value: {line.strip()}\")\n",
    "                                continue\n",
    "                            # add data to dataframe\n",
    "                            data.results.loc[len(data.results)] = {\n",
    "                                \"decoder\": decoder,\n",
    "                                \"depth\": depth,\n",
    "                                \"p\": p,\n",
    "                                \"value\": value\n",
    "                            }\n",
    "                                \n",
    "        steps_file_pattern = re.compile(r\"(\\w+)_d=(\\d+)_p=(\\d+.\\d+)\\.txt\")\n",
    "        for file in steps_files: \n",
    "            steps_match = steps_file_pattern.match(os.path.basename(file))\n",
    "            if not steps_match:\n",
    "                continue\n",
    "            decoder, depth, p = steps_match.groups()\n",
    "            depth = int(depth)\n",
    "            p = float(p)\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 2:\n",
    "                            key, value = parts\n",
    "                            try:\n",
    "                                steps = float(key)\n",
    "                                occurences = int(value)\n",
    "                            except ValueError:\n",
    "                                print(f\"Skipping line with non-numeric key or value: {line.strip()}\")\n",
    "                                continue\n",
    "                            # add data to dataframe\n",
    "                            data.steps.loc[len(data.steps)] = {\n",
    "                                \"decoder\": decoder,\n",
    "                                \"depth\": depth,\n",
    "                                \"p\": p,\n",
    "                                \"value\": steps,\n",
    "                                \"occurences\": occurences\n",
    "                            }\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "790cb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_plot(results):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for (decoder, depth), values in results.items():\n",
    "        colors = decoder_colors.get(decoder)\n",
    "        decoder_name = decoder_names.get(decoder)\n",
    "        x = list(values.keys())\n",
    "        y = list(values.values())\n",
    "        sorted_indices = np.argsort(x)\n",
    "        \n",
    "        x = np.array(x)[sorted_indices]\n",
    "        y = np.array(y)[sorted_indices]\n",
    "        \n",
    "        # Compute Wilson score uncertainties\n",
    "        # phat is the estimated proportion of failures\n",
    "        z = norm.ppf(1 - 0.05 / 2)  # for 95% confidence\n",
    "        n = 200000 \n",
    "        sigma = [1 / (1 + z**2 / n) * (phat + z/(2*n)*(z + np.sqrt(4*n*phat*1-phat)+z**2)) for phat in y]\n",
    "        sigma = np.array(sigma)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=sigma,\n",
    "                visible=False,\n",
    "                thickness=1.5,\n",
    "                width=3\n",
    "            ),\n",
    "            mode='lines+markers',\n",
    "            name=f\"{decoder_name} d={depth}\",\n",
    "            line=dict(color=colors[depth % len(colors)], width=2),\n",
    "            marker=dict(size=5),\n",
    "            legendgroup=decoder_name,\n",
    "            legendgrouptitle_text=decoder_name,\n",
    "            hovertemplate=f\"{decoder_name} d={depth}<br>p: %{{x:.2e}}<br>L: %{{y:.2e}}\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "                \n",
    "\n",
    "        if len(x) < 2:\n",
    "            print(f\"Not enough data points for fitting for {decoder_name} d={depth}\")\n",
    "            continue\n",
    "\n",
    "        def power_law(x, a, b):\n",
    "            return a * np.power(x, b)\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(\n",
    "                power_law, x, y, sigma=sigma, absolute_sigma=True\n",
    "            )\n",
    "            a, b = popt\n",
    "            print(f\"{decoder_name} d={depth}, (d+1)/2={(depth+1)/2}, b={b:.4f}\")\n",
    "            fit_x = np.linspace(min(x), max(x), 100)\n",
    "            fit_y = power_law(fit_x, *popt)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=fit_x,\n",
    "                y=fit_y,\n",
    "                mode='lines',\n",
    "                name=f\"{decoder_name} fit d={depth}\",\n",
    "                line=dict(color=colors[depth % len(colors)], width=1, dash='dash'),\n",
    "                legendgroup=f\"{decoder_name} fit\",\n",
    "                legendgrouptitle_text=f\"{decoder_name} fit\",\n",
    "                hovertemplate=f\"{decoder_name} fit d={depth}: <br> parameters: c={b:.4f}<br> d/2={(depth)/2}\",\n",
    "                showlegend=True,\n",
    "            ))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting data for {decoder_name} d={depth}: {e}\")\n",
    "        \n",
    "    # Set legend groups ending with fit to not selected by default\n",
    "    for trace in fig.data:\n",
    "        if 'fit' in trace.name:\n",
    "            trace.visible = 'legendonly'\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Results\",\n",
    "        legend_title=\"Decoder\",\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(type='log', title='p (log scale)'),\n",
    "        yaxis=dict(type='log', title='L (log scale)'),\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f18265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8590/1972510568.py:4: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClAYG d=4, (d+1)/2=2.5, b=1.7267\n",
      "ClAYG d=6, (d+1)/2=3.5, b=1.9987\n",
      "ClAYG d=8, (d+1)/2=4.5, b=1.9733\n",
      "ClAYG ⅓ Growth d=4, (d+1)/2=2.5, b=0.9211\n",
      "ClAYG ⅓ Growth d=6, (d+1)/2=3.5, b=1.2076\n",
      "ClAYG ⅓ Growth d=8, (d+1)/2=4.5, b=1.3670\n",
      "Opening in existing browser session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[9407:9407:0716/191001.580930:ERROR:ui/gl/gl_surface_presentation_helper.cc:260] GetVSyncParametersIfAvailable() failed for 1 times!\n",
      "[9407:9407:0716/191004.030244:ERROR:ui/gl/gl_surface_presentation_helper.cc:260] GetVSyncParametersIfAvailable() failed for 2 times!\n",
      "[9407:9407:0716/191054.842409:ERROR:ui/gl/gl_surface_presentation_helper.cc:260] GetVSyncParametersIfAvailable() failed for 3 times!\n"
     ]
    }
   ],
   "source": [
    "# Plot results for the tests with different growth rates\n",
    "base_dir = \"data/old/special_clayg_tests\"\n",
    "average_operations = collect_data_old(base_dir, [2])\n",
    "results = average_operations.loc[(average_operations['metric'] == 'results') & (average_operations['p'] > 0) & (average_operations['value'] > 0)].groupby(['decoder', 'depth']).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "\n",
    "\n",
    "fig = threshold_plot(results)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results for the tests with clayg with faster backwards growth\n",
    "base_dir = \"data/old/special_clayg_grow_faster_backwards\"\n",
    "average_operations = collect_data_old(base_dir, [1])\n",
    "print(len(average_operations))\n",
    "average_operations = average_operations.loc[(average_operations['metric'] == 'results') & (average_operations['p'] > 0) & (average_operations['value'] > 0)]\n",
    "results = average_operations.groupby(['decoder', 'depth'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = threshold_plot(results)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8db186d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClAYG d=4, (d+1)/2=2.5, b=1.8692\n",
      "ClAYG d=6, (d+1)/2=3.5, b=2.4928\n",
      "ClAYG d=8, (d+1)/2=4.5, b=2.7345\n",
      "ClAYG d=10, (d+1)/2=5.5, b=4.1724\n",
      "Single Layer ClAYG d=4, (d+1)/2=2.5, b=1.8643\n",
      "Single Layer ClAYG d=6, (d+1)/2=3.5, b=2.4920\n",
      "Single Layer ClAYG d=8, (d+1)/2=4.5, b=2.6218\n",
      "Single Layer ClAYG d=10, (d+1)/2=5.5, b=3.7079\n",
      "UF d=4, (d+1)/2=2.5, b=1.9729\n",
      "UF d=6, (d+1)/2=3.5, b=3.1165\n",
      "UF d=8, (d+1)/2=4.5, b=4.0940\n",
      "UF d=10, (d+1)/2=5.5, b=5.8422\n",
      "Opening in existing browser session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4869/1687807362.py:5: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot results for the tests with single layer clayg\n",
    "base_dir = \"data/old/single_layer_clayg_tests\"\n",
    "average_operations = collect_data_old(base_dir, [1,2,3])\n",
    "average_operations = average_operations.loc[(average_operations['metric'] == 'results') & (average_operations['p'] > 0) & (average_operations['value'] > 0)]\n",
    "results = average_operations.groupby(['decoder', 'depth'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = threshold_plot(results)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4869/2470330830.py:7: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "/tmp/ipykernel_4869/2470330830.py:12: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n",
      "/tmp/ipykernel_4869/2470330830.py:30: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "base_dir = \"data/new_average_operations\"\n",
    "\n",
    "data = collect_data(base_dir, [1,2,3,4])\n",
    "\n",
    "steps = data.steps.groupby(['decoder', 'depth', 'p']).apply(lambda x: x.set_index('value')['occurences'].to_dict()).to_dict()\n",
    "\n",
    "avg_steps = (\n",
    "    data.steps\n",
    "    .groupby(['decoder', 'depth', 'p'])\n",
    "    .apply(lambda x: np.average(x['value'], weights=x['occurences']))\n",
    "    .reset_index(name='avg_steps')\n",
    ")\n",
    "\n",
    "average_steps_by_d = (\n",
    "    avg_steps\n",
    "    .pivot_table(index=['decoder', 'p'], columns='depth', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "average_steps_by_p = (\n",
    "    avg_steps\n",
    "    .pivot_table(index=['decoder', 'depth'], columns='p', values='avg_steps')\n",
    "    .apply(lambda row: row.dropna().to_dict(), axis=1)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "results = data.results.groupby(['decoder', 'depth']).apply(lambda x: x.set_index('p')['l'].to_dict()).to_dict()\n",
    "\n",
    "#threshold_plot(results).show()\n",
    "plot_step_distribution_by_p(steps).show()\n",
    "plot_average_operations_against_d(average_steps_by_d).show()\n",
    "#plot_average_operations_against_p(average_steps_by_p).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c80c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_average_operations_against_p(average_operations):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for (decoder, depth), values in average_operations.items():\n",
    "        colors = decoder_colors.get(decoder)\n",
    "        decoder_name = decoder_names.get(decoder)\n",
    "        x = list(values.keys())\n",
    "        y = list(values.values())\n",
    "        # sort by x\n",
    "        sorted_indices = np.argsort(x)\n",
    "        x = np.array(x)[sorted_indices]\n",
    "        y = np.array(y)[sorted_indices]\n",
    "        print(f\"Plotting {decoder_name} d={depth}, data points: {len(x)}\")\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='lines+markers',\n",
    "            name=f\"{decoder_name} d={depth}\",\n",
    "            line=dict(color=colors[depth % len(colors)], width=2),\n",
    "            marker=dict(size=5),\n",
    "            legendgroup=decoder_name,\n",
    "            legendgrouptitle_text=decoder_name,\n",
    "            hovertemplate=f\"{decoder_name} d={depth}<br>p: %{{x:.2e}}<br>avg. # of operations: %{{y:.3}}\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Average Operations\",\n",
    "        legend_title=\"Decoder\",\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(type='linear', title='p (linear scale)'),\n",
    "        yaxis=dict(type='linear', title='Average Operations (linear scale)'),\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_average_operations_against_d(average_operations):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for (decoder, p), values in average_operations.items():\n",
    "        colors = decoder_colors.get(decoder)\n",
    "        decoder = decoder_names.get(decoder)\n",
    "        x = list(values.keys())\n",
    "        y = list(values.values())\n",
    "        # sort by x\n",
    "        sorted_indices = np.argsort(x)\n",
    "        x = np.array(x)[sorted_indices]\n",
    "        y = np.array(y)[sorted_indices]\n",
    "        print(f\"Plotting {decoder} p={p}, data points: {len(x)}\")\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode='lines+markers',\n",
    "            name=f\"{decoder} p={p}\",\n",
    "            line=dict(color=colors[int(p*1000) % len(colors)], width=2),\n",
    "            marker=dict(size=5),\n",
    "            legendgroup=decoder,\n",
    "            legendgrouptitle_text=decoder,\n",
    "            hovertemplate=f\"{decoder} p={p}<br>d: %{{x}}<br>avg. # of operations: %{{y:.3}}\",\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Average Operations\",\n",
    "        legend_title=\"Decoder\",\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(type='linear', title='distance d (linear scale)'),\n",
    "        yaxis=dict(type='linear', title='Average Operations (log scale)'),\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_step_distribution_by_p(steps):\n",
    "    # Get all unique p values\n",
    "    ps = set(p for (_, _, p) in steps.keys())\n",
    "    if len(ps) > 1:\n",
    "        # Multiple p: group by (decoder, depth), columns for each p\n",
    "        group = defaultdict(list)\n",
    "        for decoder, depth, p in steps.keys():\n",
    "            group[(decoder, depth)].append(p)\n",
    "        row_keys = list(group.keys())\n",
    "        max_cols = max(len(ps) for ps in group.values())\n",
    "        fig = make_subplots(\n",
    "            rows=len(row_keys), cols=max_cols,\n",
    "            subplot_titles=[\n",
    "                f\"{decoder_names.get(decoder, decoder)} d={depth}, p={p:.1e}\"\n",
    "                for (decoder, depth), ps in group.items() for p in sorted(ps)\n",
    "            ],\n",
    "            horizontal_spacing=0.08, vertical_spacing=0.02\n",
    "        )\n",
    "        for row, (decoder, depth) in enumerate(row_keys, start=1):\n",
    "            ps_sorted = sorted(group[(decoder, depth)])\n",
    "            for col, p in enumerate(ps_sorted, start=1):\n",
    "                values = steps[(decoder, depth, p)]\n",
    "                x = []\n",
    "                for step_val, count in sorted(values.items()):\n",
    "                    x.extend([step_val] * count)\n",
    "                colors = decoder_colors.get(decoder)\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=x,\n",
    "                        marker_color=colors[depth % len(colors)],\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "    else:\n",
    "        # Only one p: group by decoder, columns for each depth\n",
    "        group = defaultdict(list)\n",
    "        for decoder, depth, p in steps.keys():\n",
    "            group[decoder].append(depth)\n",
    "        row_keys = list(group.keys())\n",
    "        max_cols = max(len(ds) for ds in group.values())\n",
    "        fig = make_subplots(\n",
    "            rows=len(row_keys), cols=max_cols,\n",
    "            subplot_titles=[\n",
    "                f\"{decoder_names.get(decoder, decoder)} d={depth}\"\n",
    "                for decoder, ds in group.items() for depth in sorted(ds)\n",
    "            ],\n",
    "            horizontal_spacing=0.08, vertical_spacing=0.04\n",
    "        )\n",
    "        for row, decoder in enumerate(row_keys, start=1):\n",
    "            ds_sorted = sorted(group[decoder])\n",
    "            for col, depth in enumerate(ds_sorted, start=1):\n",
    "                # Since only one p, get it\n",
    "                p = next(p for (d, dep, p) in steps.keys() if d == decoder and dep == depth)\n",
    "                values = steps[(decoder, depth, p)]\n",
    "                x = []\n",
    "                for step_val, count in sorted(values.items()):\n",
    "                    x.extend([step_val] * count)\n",
    "                colors = decoder_colors.get(decoder)\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=x,\n",
    "                        marker_color=colors[depth % len(colors)],\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "    fig.update_layout(\n",
    "        title=\"Step Distribution by Decoder, Depth, and p\",\n",
    "        template=\"plotly_white\",\n",
    "        height=300 * len(row_keys),\n",
    "        width=500 * max_cols\n",
    "    )\n",
    "    for i in range(1, len(row_keys) + 1):\n",
    "        fig.update_yaxes(title_text=\"Count\", row=i, col=1)\n",
    "    for j in range(1, max_cols + 1):\n",
    "        fig.update_xaxes(title_text=\"Steps\", row=1, col=j)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75452c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No folders found for plot_id 18\n",
      "No folders found for plot_id 19\n",
      "No folders found for plot_id 20\n",
      "No folders found for plot_id 21\n",
      "No folders found for plot_id 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4796/1624721967.py:4: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_average_operations_against_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m average_operations = collect_data_old(base_dir, [\u001b[32m18\u001b[39m,\u001b[32m19\u001b[39m,\u001b[32m20\u001b[39m,\u001b[32m21\u001b[39m, \u001b[32m22\u001b[39m])\n\u001b[32m      4\u001b[39m average_operations = average_operations.loc[average_operations[\u001b[33m'\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33maverage_operations\u001b[39m\u001b[33m'\u001b[39m].groupby([\u001b[33m'\u001b[39m\u001b[33mdecoder\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m'\u001b[39m], group_keys=\u001b[38;5;28;01mFalse\u001b[39;00m).apply(\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x.set_index(\u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m].to_dict()\n\u001b[32m      6\u001b[39m ).to_dict()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m fig = \u001b[43mplot_average_operations_against_p\u001b[49m(average_operations)\n\u001b[32m     10\u001b[39m fig.show(renderer=\u001b[33m\"\u001b[39m\u001b[33mbrowser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plot_average_operations_against_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot average operations against p\n",
    "base_dir = \"data/treshold_plots\"\n",
    "average_operations = collect_data_old(base_dir, [18,19,20,21, 22])\n",
    "average_operations = average_operations.loc[average_operations['metric'] == 'average_operations'].groupby(['decoder', 'depth'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = plot_average_operations_against_p(average_operations)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a506aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No folders found for plot_id 2\n",
      "No folders found for plot_id 3\n",
      "Plotting ClAYG d=4, data points: 35\n",
      "Plotting ClAYG d=6, data points: 35\n",
      "Plotting ClAYG d=8, data points: 35\n",
      "Plotting ClAYG w/ Faster Backwards Growth d=4, data points: 35\n",
      "Plotting ClAYG w/ Faster Backwards Growth d=6, data points: 35\n",
      "Plotting ClAYG w/ Faster Backwards Growth d=8, data points: 35\n",
      "Opening in existing browser session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9498/3290088076.py:4: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot average operations against p\n",
    "base_dir = \"data/special_clayg_grow_faster_backwards\"\n",
    "average_operations = collect_data_old(base_dir, [1,2,3])\n",
    "average_operations = average_operations.loc[average_operations['metric'] == 'average_operations'].groupby(['decoder', 'depth'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('p')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = plot_average_operations_against_p(average_operations)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ff616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting ClAYG p=0.0001, data points: 13\n",
      "Plotting ClAYG p=0.0005, data points: 13\n",
      "Plotting ClAYG p=0.001, data points: 13\n",
      "Plotting UF p=0.0001, data points: 13\n",
      "Plotting UF p=0.0005, data points: 13\n",
      "Plotting UF p=0.001, data points: 13\n",
      "Opening in existing browser session.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9498/4209233391.py:4: FutureWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot average operations against d\n",
    "base_dir = \"data/average_operations_initial\"\n",
    "data = collect_data_old(base_dir, [2,3])\n",
    "average_operations = data.loc[data['metric'] == 'average_operations'].groupby(['decoder', 'p'], group_keys=False).apply(\n",
    "    lambda x: x.set_index('depth')['value'].to_dict()\n",
    ").to_dict()\n",
    "\n",
    "fig = plot_average_operations_against_d(average_operations)\n",
    "\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdee18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
